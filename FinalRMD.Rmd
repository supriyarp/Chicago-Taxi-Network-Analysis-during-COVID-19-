---
title: "FinalRMD"
author: "Supriya"
date: "11/27/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

install.packages('RJSONIO')
install.packages('gridExtra')
install.packages('RSocrata')
```{r, message=FALSE}
library(dplyr)
library(tidyr) 
library(RJSONIO)
library(jsonlite)
library(tidyverse)
library(data.table)
library(ggplot2)
library(gridExtra)
library(igraph)
library(forcats)
library(ggpubr)
```

#Read data
```{r}
data <- read.csv("raw.csv", header = T, sep = ",")
nrow(data)
colnames(data)
```
#Data Cleaning
```{r}
#Cleaning the data: Remove NAs 
data[data== "NULL"] <- "NA"

#Different Taxi companies
print("Different Taxi companies: ")
unique(data$company)

#dropping some variables which are not necessary 
drop <- c("pickup_census_tract","dropoff_census_tract","extras","pickup_centroid_location.type","pickup_centroid_location.coordinates","dropoff_centroid_location.type","dropoff_centroid_location.coordinates","company","payment_type","tips","taxi_id","trip_id")
data = data[,!(names(data) %in% drop)]
data <- na.omit(data, cols=seq_along(c('pickup_community_area', 'dropoff_community_area')))
str(data)
```
```{r}
#Breaking time stamp to date and time
data$Time <- format(as.POSIXct(data$trip_start_timestamp),
                    format = "%H:%M:%S" )
data$Date <- format(as.POSIXct(data$trip_start_timestamp),
                    format = "%Y-%m-%d" )
data$trip_miles[is.na(data$trip_miles)] <- 0
```

#Trips in Months & Weekdays of Summer20
```{r}
#Converting date to a proper retrievable format
data$Date <- as.Date(data$Date)
data$month <- months.Date(data$Date)

data$month <- factor(data$month,levels=c("May","June","July","August","September"))
busy_month <- data %>% group_by(month) %>% summarise(count=n())
busy_month$month <- factor(busy_month$month,levels=month.name)
busy_month

data$weekday <- weekdays(data$Date)%>%factor(levels = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))
set.seed(100)
data$hour = as.numeric(strtrim(data$Time, nchar(data$Time) - 6)) 


ggplot(data,aes(x = month,fill=month))+geom_bar(colour = "black", position = "stack") + scale_fill_brewer(palette = "OrRd")+ggtitle("Total number of trips each month in Summer20")+scale_x_discrete(limits = c("May","June","July","August","September"))+ scale_y_continuous(labels = function(x) format(x, scientific = FALSE))

#No. of trips on each day
ggplot(data,aes(x = weekday,fill=weekday))+geom_bar(colour = "black", position = "stack") + scale_fill_brewer(palette = "RdPu")+ggtitle("Total number of trips each month in Summer20")+scale_x_discrete(limits = c('Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday'))+ scale_y_continuous(labels = function(x) format(x, scientific = FALSE))
```

#Fare amounts
```{r}
fare = as.numeric(data$fare)
ggplot(data,aes(x= fare))+
  geom_line(stat = 'count')+
  labs(x= "Fare Amounts")+
  scale_x_continuous(limits = c(0,50))+ scale_y_continuous(labels = function(x) format(x, scientific = FALSE))+theme_minimal()
```
#Busy hours
```{r}
ggplot(data,aes(x = hour ))+
  geom_line(stat = 'count')+
  labs(x= "hour of the day")+
  scale_x_discrete(limits = c(0:23))+labs(title = "Number of trips per hour")

#Busy Hours
table(data[,c("weekday", "hour")]) %>%
  as.data.frame() %>%
  ggplot() +
  aes(x=weekday, y=hour, fill=Freq) + scale_fill_gradient(low="white", high="deepskyblue4")+
  geom_tile() +  labs(title = "Heatmap of number of trips for hour of the Weekday")

```
#Cost vs Duration
```{r}

ggplot(data, aes(trip_total, trip_seconds, color = trip_total)) +
  geom_point(shape = 16, size = 3, show.legend = FALSE, alpha = .4) + coord_cartesian(xlim = c(0,400), ylim = c(0, 20000)) +
  labs(title = "Cost vs Duration")

```

# Subsetting required variables for graph
```{r}
select <- c("pickup_centroid_location.coordinates", "dropoff_centroid_location.coordinates",
            "pickup_centroid_latitude", "pickup_centroid_longitude", 'pickup_community_area', 'dropoff_community_area',
            'trip_miles', 'trip_seconds', 'fare', 'tip', 'trip_total',"trip_start_timestamp")

#pickup_community_area and dropoff_community_area are nodes
df <- data[,select[5:6]]
```

#Creating the graph and converting them to simplified graph
```{r}
g_net <- graph.data.frame(df, directed = T)
E(g_net)$weight <- 1

vcount(g_net)
ecount(g_net)

is.simple(g_net)
g_simple <- simplify(g_net, edge.attr.comb="sum")

#re-scaling the graph for better plot:
V(g_simple)$color <- "grey"

#https://stackoverflow.com/questions/40725269/r-igraph-scaling-node-size
rescale = function(x,a,b,c,d){c + (x-a)/(b-a)*(d-c)}
plot(g_simple, edge.width = rescale(E(g_simple)$weight,1,9000, 0.001, 10 ) , vertex.size = rescale(degree(g_simple, mode = "out"), 25, 77, 0.001, 10), main = "Simplified Chicago 2020 Summer Taxi Network", vertex.label = NA, edge.arrow.size=0.04 , edge.lty="solid", edge.color="navyblue")
```

# Sub-graph with less than 100 trips (main graph on which analysis is based)
```{r}
g_sub <- subgraph.edges(g_simple, E(g_simple)[E(g_simple)$weight<100], del=F)
g_sub1 <- delete_vertices(g_sub, degree(g_sub, mode = "in")==0)

vcount(g_sub1)
ecount(g_sub1)

plot(g_sub1, edge.width = rescale(E(g_sub1)$weight, 1,4000, 0.001, 10) , vertex.size = rescale(degree(g_sub1, mode = "out"), 0,77, 0.1, 10), main = "Chicago Taxi Network - less than 100 Trips",vertex.label = NA, edge.arrow.size=0.04 , edge.lty="solid", edge.color="navyblue")
```

# Subgraph with more than 100 trips (main graph on which analysis is based)
```{r}
g_suba <- subgraph.edges(g_simple, E(g_simple)[E(g_simple)$weight>100], del=F)
g_sub2 <- delete_vertices(g_suba, degree(g_suba, mode = "in")==0)

vcount(g_sub2)
ecount(g_sub2)

plot(g_sub2, edge.width = rescale(E(g_sub1)$weight, 1, 5000, 0.001, 10 ) , vertex.size = rescale(degree(g_sub2, mode = "out"), 0,77, 0.1, 10), main = "Chicago Taxi Network - More than 100 Trips", vertex.label = NA, edge.arrow.size=0.01 , edge.lty="solid", edge.color="navyblue")
```

```{r}
# Subgraph with more than 500 trips (main graph on which analysis is based)
g_subb <- subgraph.edges(g_simple, E(g_simple)[E(g_simple)$weight>500], del=F)
g_sub3 <- delete_vertices(g_subb, degree(g_suba, mode = "in")==0)

vcount(g_sub3)
ecount(g_sub3)

plot(g_sub3, main = "Chicago Taxi Network - More than 500 Trips", vertex.label = NA , edge.lty="solid", edge.color="navyblue", vertex.size = rescale(degree(g_sub3, mode = "out"), 0, 10, 0.001, 10),edge.arrow.size=0.1,layout= layout.kamada.kawai,edge.width = rescale(E(g_sub1)$weight, 1, 750, 0.001, 10 ) )
```
## Understanding the networks through following: 
#1. Diameter
#2. Avg path length
#3. Connectivity
#4. Transitivity
#5. Reciprocity

```{r}
#Creating feature data frame to have all the features of the graphs----
features = data.frame(Name= character(4),Edges= numeric(4),Vertices=numeric(4),Diameter=numeric(4),                                 Avg_path_length = numeric(4), Verticex_connectivity = numeric(4), 
                     Edge_connectivity = numeric(4), Global_Clustering_Coefficient = numeric(4), 
                     Reciprocity = numeric(4),Network_Density= numeric(4), 
                     Is_connected = logical(4),Is_connected_Strong = logical(4),
                    Is_connected_Weak = logical(4))

graph_names= c("Chicago_Taxi_Network",
              "Chicago_Taxi_Network_<100",
              "Chicago_Taxi_Network_>100",
              "Chicago_Taxi_Network_>500")

#Tabulating the results
for (i in 1:4){
  features[i,1] = graph_names[i]
  if(i==1)
  {g=g_simple }
    if(i==2)
    {g=g_sub1}
      if(i==3)
      {g=g_sub2}
    if(i==4)
      {g=g_sub3}
    features[i,2] = ecount(g)
    features[i,3] = vcount(g)
    features[i,4] = diameter(g)
    features[i,5] = average.path.length(g)
    features[i,8] = transitivity(g)
    features[i,6] = vertex.connectivity(g)
    features[i,7] = edge.connectivity(g)
    features[i,9] = reciprocity(g)
    features[i,10] = graph.density(g)
    features[i,11] = is.connected(g)
    features[i,12] = is.connected(g , mode="strong")
    features[i,13] = is.connected(g , mode="weak") 
}
#Check out feature data frame for the above measures
view(features)
```

#Understanding graph with >100 trips
```{r}
#The strongly connected components are implemented by two consecutive depth-first searches.     ->
print("Calculating the maximal (strongly) connected components of a graph:")
clusters(g_sub2, mode = 'strong')
# 8

#csize:	numeric vector giving the sizes of the clusters.
#no:	numeric constant, the number of clusters.

#Number of strongly connected components            ->
g_sub2.scc <- clusters(g_sub2, mode="strong")
print("Number of strongly connected components")
table(g_sub2.scc)

#Number of weakly connected components              ->
g_sub2.wcc <- clusters(g_sub2, mode="weak")
print("Number of weakly connected components")
table(g_sub2.wcc$csize)


#Node degrees                                       ->
in.deg <- degree(g_sub2,v=V(g_sub2),mode="in")
out.deg <- degree(g_sub2,v=V(g_sub2),mode="out")
total.deg <- degree(g_sub2,v=V(g_sub2),mode="all")
table(total.deg)

#Max In Degree Node
max(degree(g_sub2, mode='in')) # Gives max indegree in network
V(g_sub2)$name[degree(g_sub2, mode='in')==max(degree(g_sub2, mode='in'))] # gives the corresponding node
degree(g_sub2,mode='in')['28'] # Total degrees of this user

#Max Out Degree Node
max(degree(g_sub2, mode='out')) # Gives max outdegree in network
V(g_sub2)$name[degree(g_sub2, mode='out')==max(degree(g_sub2, mode='out'))] # gives the corresponding node

degree(g_sub2,mode='out')['28'] # Total degrees of this node

#Mean Degree
mean(degree(g_sub2))
table(degree(g_sub2, mode="in"))
table(degree(g_sub2, mode="out"))

# Degree Distribution
deg_d_gsim <- degree.distribution(g_simple, cumulative = T)
plot(deg_d_gsim, log = 'xy', bg = 'black', xlab = 'Degree', ylab = 'Cumulative Frequency', main = "Degree Distribution of Chicago_Taxi_Network")

deg_d_gsub <- degree.distribution(g_sub2, cumulative = T)
plot(deg_d_gsub, log = 'xy', bg = 'black', xlab = 'Degree', ylab = 'Cumulative Frequency', main = "Degree Distribution > 100 trips")

# Histogram
hist(degree(g_simple, mode = "out"), col="blue", xlab="Degree", ylab="Frequency", main="Degree Distribution: Chicago_Taxi_Network")
hist(degree(g_sub2, mode = "out"), col="blue", xlab="Degree", ylab="Frequency", main="Degree Distribution: Chicago_Taxi_Network > 100 trips")

#17. Local clustering coefficients
clustering_SAP <- transitivity(g_sub2, type="local") 
print("Max: Local clustering coefficients")
Max_lc <- which(clustering_SAP == max(clustering_SAP, na.rm = T), arr.ind = T)
table(Max_lc)
```
```{r}
# Strength of Network
strengthout <- strength(g_sub2, vids = V(g_sub2), mode = c( "out"), loops = TRUE)
strengthin <- strength(g_sub2, vids = V(g_sub2), mode = c( "in"), loops = TRUE)
sprintf("Node with Min(Strength of out degree): %d",length(which(strengthout == min(strengthout), arr.ind = T)))
sprintf("Node with Min(Strength of in degree): %d",length(which(strengthin == min(strengthin), arr.ind = T)))

#Histogram for Distribution of vertex strength
par(mfrow=c(2,1))
# InDegree
hist(graph.strength(g_sub2, mode='in'), col="cyan3",
     xlab="Vertex Strength", ylab="Frequency", 
     main="Vertex Strength Distribution: InDegree",
     breaks = 30)
# OutDegree
hist(graph.strength(g_sub2, mode='out'), col="lightblue",
     xlab="Vertex Strength", ylab="Frequency", 
     main="Vertex Strength Distribution: OutDegree",
     breaks = 30)

#dev.off()

#Degree centrality
#Degree centrality-OUT
degree_sap <- degree(g_sub2, mode = "out")
print("Degree centrality-OUT")
which(degree_sap == max(degree_sap), arr.ind = T)
# 28 
# 10 
#Degree centrality-IN
degree_sapin <- degree(g_sub2, mode = "in")
print("Degree centrality-IN")
which(degree_sapin == max(degree_sapin), arr.ind = T)
# 28 
# 10 

#11c Using ego function to visualise 28
ego.list <- make_ego_graph(g_sub2, order=1, nodes=V(g_sub2)['28'])

desired_subset <- NULL
for (i in seq_along(ego.list)){
  x <- ego.list[[i]]
  desired_subset <- graph.union(desired_subset, x)
}
V(desired_subset)$color<-"yellow"
V(desired_subset)['28']$color<-"blue"
plot(desired_subset,vertex.size=4, layout=layout_nicely,main = "Degree Centrality of node 28",edge.arrow.size = 0.1,  edge.lty="solid", edge.color="grey")

#Closeness Centrality
close_SAP <- closeness(g_sub2)
which(close_SAP == max(close_SAP), arr.ind = T)

#12. Betweeness 
betweens_SAP <- round(betweenness(g_sub2, v=V(g_sub2), directed = TRUE, nobigint =TRUE, normalized = FALSE))
which(betweens_SAP == max(betweens_SAP), arr.ind = T)
#70 60 27 29 26 67 48 12 59 51 31  9 20 45 30 64 
# 9 17 18 22 24 31 32 46 48 53 56 57 58 60 61 62 

```
#Understanding majority pick-up and drop-off areas in chicago
```{r}
df7 <- data[,c("pickup_community_area", "dropoff_community_area", "pickup_centroid_latitude", "pickup_centroid_longitude")]
df9 <- data[,c("pickup_community_area", "dropoff_community_area", "dropoff_centroid_latitude", "dropoff_centroid_longitude")]
df7 <- as.data.frame(lapply(df7, function(x) as.numeric(as.character(x))))

df7 <- df7[as.character(df7$pickup_community_area) %in% V(g_sub2)$name,]

df8 <- df7 %>% group_by(pickup_community_area) %>% summarise(count=n(),latpickup = mean(pickup_centroid_latitude), longpickup = mean(pickup_centroid_longitude))
arrange(df8,desc(count))
df9 %>% group_by(dropoff_community_area) %>% summarise(count=n(),latpickup = mean(dropoff_centroid_latitude), longpickup = mean(dropoff_centroid_longitude))%>%arrange(desc(count))

```

```{r}
cord_df <- as.matrix(df8[,c("longpickup", "latpickup")])

name_v <- c('1'='Rogers Park', '2'='West Ridge', '3'='Uptown', '4'='Lincoln Square', '5'='North Center', '6'='Lakeview', '7'='Lincoln Park', '8'='Near North Side', '9'='Edison Park', '10'='Norwood Park', '11'='Jefferson Park', '12'='Forest Glen', '13'='North Park', '14'='Albany Park', '15'='Portage Park', '16'='Irving Park', '17'='Dunning', '18'='Montclare', '19'='Belmont Cragin', '20'='Hermosa', '21'='Avondale', '22'='Logan Square', '23'='Humboldt Park', '24'='West Town', '25'='Austin', '26'='West Garfield Park', '27'='East Garfield Park', '28'='Near West Side', '29'='North Lawndale', '30'='South Lawndale', '31'='Lower West Side', '32'='Loop', '33'='Near South Side', '34'='Armour Square', '35'='Douglas', '36'='Oakland', '37'='Fuller Park', '38'='Grand Boulevard', '39'='Kenwood', '40'='Washington Park', '41'='Hyde Park', '42'='Woodlawn', '43'='South Shore', '44'='Chatham', '45'='Avalon Park', '46'='South Chicago', '47'='Burnside', '48'='Calumet Heights', '49'='Roseland', '50'='Pullman', '51'='South Deering', '52'='East Side', '53'='West Pullman', '54'='Riverdale', '55'='Hegewisch', '56'='Garfield Ridge', '57'='Archer Heights', '58'='Brighton Park', '59'='McKinley Park', '60'='Bridgeport', '61'='New City', '62'='West Elsdon', '63'='Gage Park', '64'='Clearing', '65'='West Lawn', '66'='Chicago Lawn', '67'='West Englewood', '68'='Englewood', '69'='Greater Grand Crossing', '70'='Ashburn', '71'='Auburn Gresham', '72'='Beverly', '73'='Washington Heights', '74'='Mount Greenwood', '75'='Morgan Park', '76'='O-Hare', '77'='Edgewater' )

V(g_sub2)$label <- name_v[V(g_sub2)$name]


plot(g_sub2, layout = cord_df, edge.width = rescale(E(g_sub2)$weight, 25, 20000, 0.001, 10 ), vertex.size = rescale(degree(g_sub2, mode = "out"), 0, 62, 0.1, 10), axes = TRUE, asp = 0, vertex.label.cex = 0.5, rescale = F,  xlim=c(-87.90, -87.52), ylim=c(41.70, 42.03), xlab = "Longitude", ylab = "Latitude", edge.arrow.size=0.02 , edge.lty="solid", edge.color="navyblue")

```

```{r}
graph <- clusters(g_sub2, mode = c("strong"))

#Plot shows the clusters of chicago network>100 trips
plot(g_sub2, mark.groups = split(1:vcount(g_sub2), graph$membership),layout= layout.kamada.kawai,  vertex.size = rescale(degree(g_sub2,mode = "total"),  0, 62, 0.1, 15),edge.width= rescale(E(g_sub2)$weight, 25, 7000, 0.001, 1 ), edge.arrow.size=0.1, vertex.label.cex = 0.5, rescale = T, )

plot(g_sub2, mark.groups = split(1:vcount(g_sub2), graph$membership), layout = cord_df, vertex.size = rescale(degree(g_sub2, mode = "out"),  0, 62, 0.1, 10), edge.arrow.size=0.02, axes = TRUE,  xlim=c(-87.90, -87.52), ylim=c(41.70, 42.03),asp = 0, vertex.label.cex = 0.5, rescale = F, edge.width= rescale(E(g_sub2)$weight, 25, 20000, 0.001, 10 ), xlab = "Longitude", ylab = "Latitude",edge.lty="solid", edge.color="navyblue")

count_components(g_sub2, mode = "strong")

count_components(g_sub2, mode = "weak")


#label propogation
label_1<-cluster_label_prop(g_sub2, weights = E(g_sub2)$weight, fixed = NULL, initial = NULL)

plot(label_1, g_sub2, layout = cord_df, vertex.size = rescale(degree(g_sub2, mode = "out"), 0, 25, 0.0001, 3), edge.arrow.size=F, axes = TRUE,  xlim=c(-87.92, -87.55), ylim=c(41.65, 42.05), asp = 0, vertex.label.cex = 0.5, rescale = F, edge.width= rescale(E(g_sub2)$weight, 100,20000, 0.001, 10 ), xlab = "Longitude", ylab = "Latitude",vertex.label.cex = 0.5,)
```


#Degree Distribution

```{r}
hist(degree(g_net, mode = "out"), col="blue", xlab="Degree", ylab="Frequency", main="Degree Distribution: Complete network")

hist(degree(g_sub2, mode = "out"), col="blue", xlab="Degree", ylab="Frequency", main="Degree Distribution: network with more than 100 rides")
```


#Random or Preferential attachment study 
```{r}
# Checking degree distribution
deg_d_g_sub2 <- degree.distribution(g_sub2, cumulative = T, mode = "Out")
plot(deg_d_g_sub2, log = 'xy', bg = 'black', xlab = 'Degree', ylab = 'Cumulative Frequency', main = "Degree Distribution of Network with more than 100 trips")
```

#Looking at above plot it might be hybrid network with both preferential and random network!
```{r}
# Checking nearest neighbor node distribution
a.nn.deg.g_sub2 <- graph.knn(g_sub2,V(g_sub2))$knn

plot(degree(g_sub2), a.nn.deg.g_sub2, log="xy", 
     col="goldenrod", xlab=c("Log Vertex Degree"),
     ylab=c("Log Average Neighbor Degree"), main="Neighbor Network Node Degree Distribution for network > 100 trips")

```

#This network is not preferential network (Scale free)

```{r}
lcc <- g_sub2
# Lets check out some centrality measures
deg_lcc <- degree(lcc)

bet_lcc <- betweenness(lcc)

clo_lcc <- closeness(lcc)

tra_lcc <- transitivity(lcc, type = "local")

eig_lcc <- evcent(lcc)


data_pt = data.frame(degree = deg_lcc, closeness = clo_lcc, betweenness = bet_lcc)
plot(data_pt)
```

```{r}
plot(eig_lcc$vector, bet_lcc, main = "Betweenness vs Eigen Vector Centrality Plot", ylab = "Betweenness", xlab = "Eigen Vector Centralities")
text(eig_lcc$vector, bet_lcc, cex = 0.4, pos = 4)
```

```{r}
lccp <- lcc
V(lccp)$labels = NA
V(lccp)[1]$labels = 8
V(lccp)[10]$labels = 28
V(lccp)[5]$labels = 32
E(lccp)$color = "grey"
V(lccp)$shape = "circle"

plot(lccp, layout = cord_df, edge.width = rescale(E(g_sub2)$weight, 1, 20000, 0.001, 10 ) , vertex.size = rescale(degree(g_sub2, mode = "out"), 0,77, 0.1, 10), vertex.label = V(lccp)$labels, vertex.shape = V(lccp)$shape, vertex.size = 3, edge.arrow.size=F, xlim=c(-87.92, -87.55), ylim=c(41.7, 42.05),vertex.color="grey", asp = 0, vertex.label.cex = 0.9, rescale = F,  xlab = "Longitude", ylab = "Latitude", axes = TRUE,edge.color="navyblue")
```


# Plot degree distribution
```{r}

dd = degree.distribution(lcc, mode = "all", cumulative = FALSE)


# function to plot the degree distribution
plot_degree_distribution = function(graph) {
  # calculate degree
  d = degree(graph, mode = "all")
  dd = degree.distribution(graph, mode = "all", cumulative = FALSE)
  degree = 1:max(d)
  probability = dd[-1]
  # delete blank values
  nonzero.position = which(probability != 0)
  probability = probability[nonzero.position]
  degree = degree[nonzero.position]
  # plot
  plot(probability ~ degree, log = "xy", xlab = "Degree (log)", ylab = "Probability (log)", 
       col = "goldenrod", pch = 16, main = "Log-Log Degree Distribution")
}


plot_degree_distribution(lcc)
```
#Not following linear trend with log log plot and hence its not preferential attachment

# plot and fit the power law distribution
```{r}
fit_power_law = function(graph) {
  # calculate degree
  d = degree(graph, mode = "all")
  dd = degree.distribution(graph, mode = "all", cumulative = FALSE)
  degree = 1:max(d)
  probability = dd[-1]
  # delete blank values
  nonzero.position = which(probability != 0)
  probability = probability[nonzero.position]
  degree = degree[nonzero.position]
  reg = lm(log(probability) ~ log(degree))
  cozf = coef(reg)
  power.law.fit = function(x) exp(cozf[[1]] + cozf[[2]] * log(x))
  alpha = -cozf[[2]]
  R.square = summary(reg)$r.squared
  print(paste("Alpha =", round(alpha, 3)))
  print(paste("R square =", round(R.square, 3)))
  # plot
  plot(probability ~ degree, log = "xy", xlab = "Degree (log)", ylab = "Probability (log)", 
       col = 1, main = "Degree Distribution")
  curve(power.law.fit, col = "red", add = T, n = length(d))
}


fit_power_law(lcc)


```
```{r}
library(IDPmisc)
# Lets calculate alphas'
F_d <- ecdf(degree(lcc))
degree_lc <- degree(lcc)
tab_degree <- data.frame(table(degree_lc))


csum <- cumsum(tab_degree$Freq)
F_d <- csum/sum(tab_degree$Freq)

# Cumulative degree frequency plot
plot(F_d)

avg.degree.lcc <- mean(degree(lcc))
# 2.342


alpha_0 <- 0.11

m.mac <- 0.5*avg.degree.lcc

y <- log(1 - F_d)
#onmit Inf
```

```{r}
y <- y[1:length(y)-1]
d <- as.numeric(levels(tab_degree$degree_lc))
x_1 <- (2*alpha_0*m.mac)/(1-alpha_0)
x_1.2 <- d + x_1
x <- log(x_1.2)
x <- x[1:length(x)-1]
model.mac<-lm(y~x)
model.mac$coefficients
# (Intercept)     x[1:22] 
#    2.043241   -1.125508 
```

```{r}
alpha_0<-0.1
x_1<-(2*alpha_0*m.mac)/(1-alpha_0)
x_1.2<-d+x_1
x<-log(x_1.2)
x <- x[1:length(x)-1]
model.mac2<-lm(y~x)
beta<-model.mac2$coefficients[2]
alpha_1<-1+2/beta
alpha_1  #-0.8169181 for alpha1
```


```{r}

library(rlist)
alpha_0<-seq(0,0.9,0.1)
alpha_0<-list.append(alpha_0,c(0.99,0.999)) 
# calculate x values for each alpha_0  and plot the x lists
xset<-list()
par(mfrow=c(3,4))
for (i in 1:12){
  x_1<-(2*alpha_0[i]*m.mac)/(1-alpha_0[i])
  x_1.2<-d+x_1
  x<-log(x_1.2)
  boxplot(x)
  xset<-list.append(xset,x)
}
```

```{r}

#now calculating beta value and alpha_1

#remove any inf in x 
x_1<-xset[1]
x_1[[1]][1]<-NA
xset[1]<-x_1
y[33] <- NA
alpha1_list<-list()

for(i in 1:12){
  model.mac<-lm(y~as.matrix(xset[[i]]))
  beta<-model.mac$coefficients[2]
  alpha_1<- 1+(2/beta)
  alpha1_list<-list.append(alpha1_list,alpha_1)
  
}

a<-as.data.frame(alpha1_list)

plot(unlist(a)~alpha_0,xlab='Alpha_0',ylab='Alpha_1 estimated') + abline(a= 0, b = 1)



```


